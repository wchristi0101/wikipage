/*
 * Wikipedia API
 *
 * This is an api that searches a wikipage
 *
 * API version: 1.0.1
 * Contact: bchristian14@gmail.com
 * Generated by: Swagger Codegen (https://github.com/swagger-api/swagger-codegen.git)
 */
package swagger

import (
	"encoding/json"
	"fmt"
	"net/http"

	"github.com/gocolly/colly"
)

func WikipagesGet(w http.ResponseWriter, r *http.Request) {
	//http://localhost:8080/VoithAPI/WikipediaAPI/1.0.1/wikipages?url=https://wikipedia.org/wiki/Heidenheim_an_der_Brenz

	var url = r.URL.Query().Get("url")
	if url == "" {
		w.WriteHeader(http.StatusInternalServerError)
		w.Write([]byte("404 - Please input a url"))
		return
	}

	var sortedParams []string
	var sortParams = r.URL.Query().Get("filter")

	if sortParams != "" {
		if err := json.Unmarshal([]byte(sortParams), &sortedParams); err != nil {
			w.WriteHeader(http.StatusInternalServerError)
			w.Write([]byte("404 - Please input filter array correctly"))
			return
		}
	} else {
		sortedParams = append(sortedParams, "ImageSRCs", "WebsiteLinks", "WebsitePages", "WebsiteData")
	}

	_, foundImageSRCs := Find(sortedParams, "ImageSRCs")
	_, foundWebsiteLinks := Find(sortedParams, "WebsiteLinks")
	_, foundWebsitePages := Find(sortedParams, "WebsitePages")
	_, foundWebsiteData := Find(sortedParams, "WebsiteData")

	var message = Website{GetImageSRCs(Data{url, foundImageSRCs}), GetWebsiteLinks(Data{url, foundWebsiteLinks}), GetWebsitePages(Data{url, foundWebsitePages}), GetWebsiteData(Data{url, foundWebsiteData})}

	jsonmessage, err := json.Marshal(message)

	if err != nil {
		w.WriteHeader(http.StatusInternalServerError)
		fmt.Println(err)
		w.Write([]byte("500 - Failed to decerialized data"))
		return
	}
	w.Header().Add("Content-Type", "application/json")
	w.Write(jsonmessage)

}

func WikipagesImageSRCsGet(w http.ResponseWriter, r *http.Request) {
	w.Header().Set("Content-Type", "application/json; charset=UTF-8")
	//this does not work, use the GetImageSRCs(Data{url,true}) and then sort by filters
	w.WriteHeader(http.StatusOK)
}

func WikipagesWebsiteDataGet(w http.ResponseWriter, r *http.Request) {
	//this does not work, use the GetWebsiteData(Data{url,true}) and then sort by filters
	w.Header().Set("Content-Type", "application/json; charset=UTF-8")
	w.WriteHeader(http.StatusOK)
}

func WikipagesWebsiteLinksGet(w http.ResponseWriter, r *http.Request) {
	//this does not work, use the GetWebsiteLinks(Data{url,true}) and then sort by filters
	w.Header().Set("Content-Type", "application/json; charset=UTF-8")
	w.WriteHeader(http.StatusOK)
}

func WikipagesWebsitePagesGet(w http.ResponseWriter, r *http.Request) {
	//this does not work, use the GetWebsitePages(Data{url,true}) and then sort by filters
	w.Header().Set("Content-Type", "application/json; charset=UTF-8")
	w.WriteHeader(http.StatusOK)
}

func GetWebsiteLinks(data Data) (response *[]WebsiteLinksInner) {

	if !data.shouldReturn {
		return
	}

	c := colly.NewCollector()

	// We add Headings here
	var websiteLinksList []WebsiteLinksInner

	// count links
	c.OnHTML("a[href]", func(e *colly.HTMLElement) {
		link := e.Request.AbsoluteURL(e.Attr("href"))
		if link != "" {
			websiteLinksList = append(websiteLinksList, WebsiteLinksInner{link})
		}
	})

	c.OnError(func(r *colly.Response, err error) {
		return
	})

	c.Visit(data.url)

	return &websiteLinksList
}

func GetImageSRCs(data Data) (response *[]ImageSrCsInner) {
	// I did not name this, it was auto generated
	if !data.shouldReturn {
		return
	}

	c := colly.NewCollector()

	var imageSRCsList []ImageSrCsInner

	c.OnHTML("img", func(e *colly.HTMLElement) {
		link := e.Request.AbsoluteURL(e.Attr("src"))
		if link != "" {
			imageSRCsList = append(imageSRCsList, ImageSrCsInner{link})
		}
	})

	c.OnError(func(r *colly.Response, err error) {
		return
	})

	c.Visit(data.url)

	return &imageSRCsList
}

func GetWebsitePages(data Data) (response *[]WebsitePagesInner) {
	if !data.shouldReturn {
		return
	}

	c := colly.NewCollector()

	var listWebsiteData []WebsitePagesInner

	//This doesnt work. We need something more powerful than colly, probably goquerry.
	//The basic algorythm is search for a header tag, find all paragraph tags below it.
	//Add header to first section, and concat the paragraph tags
	c.OnHTML("p", func(e *colly.HTMLElement) {
		fmt.Println(e.DOM.Html())
		link := e.Text
		if link != "" {
			listWebsiteData = append(listWebsiteData, WebsitePagesInner{link, link})
		}
	})

	c.OnError(func(r *colly.Response, err error) {
		return
	})

	c.Visit(data.url)

	return &listWebsiteData
}

func GetWebsiteData(data Data) (response *[]WebsiteDataInner) {
	//This doesnt work. We need something more powerful than colly, probably goquerry.
	//The basic algorythm is search for mergedtoprow css class, add that as the header,
	//then keep searching down the DOM until you find the next mergedtoprow, for each item
	//before the next mergedtoprow, add an item {infobox-label,infobox-data}
	return nil
}

type Data struct {
	url          string
	shouldReturn bool
}

func Find(slice []string, val string) (int, bool) {
	for i, item := range slice {
		if item == val {
			return i, true
		}
	}
	return -1, false
}
